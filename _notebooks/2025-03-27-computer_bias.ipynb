{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title: Computer Bias\n",
    "description: Computer Bias popcorn hacks and Homework\n",
    "courses: { csp: {week:1} }\n",
    "comments: true\n",
    "sticky_rank: 1\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Idea 5 – Computing Bias  \n",
    "*Mar 17, 2025 • Avika, Gabi, Zoe*\n",
    "\n",
    "---\n",
    "\n",
    "## What is Computing Bias?\n",
    "\n",
    "**Bias**: A prejudice in favor of or against a person or group in a way that is usually unfair.  \n",
    "\n",
    "**Computing Bias** occurs when algorithms or systems produce results that disadvantage certain groups. It often arises from:\n",
    "- Biased or incomplete data\n",
    "- Flawed design\n",
    "- Unintended consequences of programming choices\n",
    "\n",
    "---\n",
    "\n",
    "## Example: Netflix Recommendation Bias\n",
    "\n",
    "Netflix uses algorithms to recommend content, but those algorithms can introduce bias by:\n",
    "\n",
    "### Majority Preference Bias\n",
    "- Recommends only popular shows, hiding niche or diverse options.\n",
    "\n",
    "### Filtering Bias\n",
    "- Filters out content based on limited viewing history.\n",
    "- If you mostly watch rom-coms, you may never see documentaries or foreign films.\n",
    "\n",
    "---\n",
    "\n",
    "## How Does Computing Bias Happen?\n",
    "\n",
    "1. **Unrepresentative or Incomplete Data**  \n",
    "   - Models trained on limited datasets don’t reflect real-world diversity.\n",
    "\n",
    "2. **Flawed or Biased Data**  \n",
    "   - If existing data includes prejudice (e.g., historical hiring patterns), the system learns and repeats those biases.\n",
    "\n",
    "3. **Biased Data Labeling**  \n",
    "   - Human annotators may unconsciously inject cultural or personal bias during labeling.\n",
    "\n",
    "---\n",
    "\n",
    "## Explicit vs. Implicit Data\n",
    "\n",
    "| Type            | Definition                               | Netflix Example                                         |\n",
    "|-----------------|-------------------------------------------|----------------------------------------------------------|\n",
    "| **Explicit Data** | Data directly provided by users           | Entering your name, age, or rating a movie              |\n",
    "| **Implicit Data** | Data inferred from user behavior          | Viewing history, time spent watching, click patterns     |\n",
    "\n",
    "### Why It Matters:\n",
    "- Implicit data can reinforce user habits, creating feedback loops that limit discovery.\n",
    "- Explicit data may still be biased if limited by design or user understanding.\n",
    "\n",
    "---\n",
    "\n",
    "## Popcorn Hack #1\n",
    "\n",
    "**Question:** What is an example of Explicit Data?  \n",
    "**Options:**  \n",
    "A) Netflix recommends shows based on your viewing history  \n",
    "B) You provide your name, age, and preferences when creating a Netflix account  \n",
    "C) Netflix tracks the time you spend watching certain genres  \n",
    "\n",
    "**Answer:** **B** – This is explicit data, because it's provided directly by the user.\n",
    "\n",
    "---\n",
    "\n",
    "## Types of Bias\n",
    "\n",
    "### Algorithmic Bias\n",
    "- Comes from faulty system logic that repeats discrimination.  \n",
    "**Example:** Amazon's hiring tool favored men because it was trained on past hiring data that was male-dominated.\n",
    "\n",
    "### Data Bias\n",
    "- Arises when training data is incomplete or unbalanced.  \n",
    "**Example:** A health AI system underestimates disease risk for underrepresented groups.\n",
    "\n",
    "### Cognitive Bias\n",
    "- Introduced by researchers or developers due to personal assumptions.  \n",
    "**Example:** A researcher only selects data supporting their belief about screen time affecting grades.\n",
    "\n",
    "---\n",
    "\n",
    "## Popcorn Hack #2\n",
    "\n",
    "**Question:** What is an example of Data Bias?  \n",
    "**Options:**  \n",
    "A) A hiring algorithm favors men due to biased past resumes  \n",
    "B) A dataset underrepresents people with darker skin tones  \n",
    "C) A researcher selects data that supports their screen time theory  \n",
    "\n",
    "**Answer:** **B** – Underrepresentation in data leads to performance issues for certain groups.\n",
    "\n",
    "---\n",
    "\n",
    "## Intentional vs. Unintentional Bias\n",
    "\n",
    "### Intentional Bias\n",
    "- Purposefully embedding prejudice to favor one group.  \n",
    "**Example:** A hiring algorithm is designed to rank resumes from certain schools or companies higher, favoring specific demographics.\n",
    "\n",
    "### Unintentional Bias\n",
    "- Occurs accidentally due to flawed datasets.  \n",
    "**Example:** A facial recognition tool trained on mostly light-skinned faces struggles to recognize darker skin tones—not due to intent, but poor data variety.\n",
    "\n",
    "---\n",
    "\n",
    "## Popcorn Hack #3\n",
    "\n",
    "**Activity:** Describe a biased scenario. Have classmates guess: was it intentional or unintentional?\n",
    "\n",
    "---\n",
    "\n",
    "## Mitigation Strategies\n",
    "\n",
    "To reduce bias in algorithms, apply these techniques at every phase:\n",
    "\n",
    "### 1. Pre-processing (Planning & Data Collection)\n",
    "- Check for data diversity and completeness\n",
    "- Remove irrelevant or biased variables\n",
    "\n",
    "**Goal:** Prepare balanced data to avoid bias in training.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. In-processing (Training & Validation)\n",
    "- Use cross-validation\n",
    "- Add synthetic data to represent minorities\n",
    "\n",
    "**Goal:** Ensure fairness during model development.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Post-processing (Deployment & Real-World Use)\n",
    "- Monitor system performance\n",
    "- Adjust output if unfair results appear\n",
    "\n",
    "**Goal:** Maintain equity as the model operates in real settings.\n",
    "\n",
    "---\n",
    "\n",
    "## Homework Questions\n",
    "\n",
    "### Multiple Choice  \n",
    "*(Each worth 0.1 points)*\n",
    "\n",
    "1. Which phase includes inserting synthetic samples?  \n",
    "2. What is an example of cognitive bias?  \n",
    "3. What’s the key difference between implicit and explicit data?  \n",
    "4. Which type of bias occurs due to flawed system logic?\n",
    "\n",
    "*(More questions provided in-class or online)*\n",
    "\n",
    "---\n",
    "\n",
    "### Short-Answer\n",
    "\n",
    "**Prompt:**  \n",
    "Explain the difference between implicit and explicit data. Give an example of each.\n",
    "\n",
    "**Scoring Rubric (Total: 1.0 point):**\n",
    "\n",
    "| Criteria                      | Description                               | Points |\n",
    "|------------------------------|-------------------------------------------|--------|\n",
    "| Multiple-Choice (7 total)    | 0.1 point each                            | 0.7    |\n",
    "| Short-Answer - Clarity       | Clear explanation                         | 0.15   |\n",
    "| Short-Answer - Examples      | Two accurate examples provided            | 0.15   |\n",
    "\n",
    "---\n",
    "\n",
    "## Suggested File Name"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
